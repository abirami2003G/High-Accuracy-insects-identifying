{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYID+BEhx0QmILApvXpp+h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ItWtCbixCH8a","executionInfo":{"status":"ok","timestamp":1703072954169,"user_tz":-330,"elapsed":25093,"user":{"displayName":"ABIRAMI G","userId":"00751295287036755883"}},"outputId":"267670dd-1227-4891-cee3-24c779a20dae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","\n","# Specify the path to your desired directory\n","path_to_directory = '/content/drive/MyDrive/core project1'\n","\n","# Change the working directory to the specified path\n","os.chdir(path_to_directory)"],"metadata":{"id":"6fzRi8_iDx8M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNetV2\n","import matplotlib.pyplot as plt"],"metadata":{"id":"IATZpnNlEENp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_dir = '/content/drive/MyDrive/core project1'\n","validation_data_dir = '/content/drive/MyDrive/core project1'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WmfVk_jbEI9Z","executionInfo":{"status":"ok","timestamp":1703073091033,"user_tz":-330,"elapsed":401,"user":{"displayName":"ABIRAMI G","userId":"00751295287036755883"}},"outputId":"e98ae61a-d659-41b8-c3bc-fde3a7933f99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 595 images belonging to 2 classes.\n","Found 595 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["base_model = MobileNetV2(input_shape=(224, 224, 3),\n","                         include_top=False,\n","                         weights='imagenet')\n","\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","x = layers.GlobalAveragePooling2D()(base_model.output)\n","x = layers.Dense(1024, activation='relu')(x)\n","output = layers.Dense(1, activation='sigmoid')(x)\n","\n","model = keras.models.Model(inputs=base_model.input, outputs=output)\n","\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),  # Increase the learning rate\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MtSo8W66EcGy","executionInfo":{"status":"ok","timestamp":1703073156412,"user_tz":-330,"elapsed":2339,"user":{"displayName":"ABIRAMI G","userId":"00751295287036755883"}},"outputId":"54f7090e-8e77-4379-84cb-4a1227756061"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9406464/9406464 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["history = model.fit(\n","    train_generator,\n","    epochs=20,\n","    validation_data=validation_generator,\n",")\n","# Assuming 'history' contains accuracy values from training\n","train_accuracy = history.history['accuracy']\n","validation_accuracy = history.history['val_accuracy']\n","\n","# Calculate the average accuracy\n","average_train_accuracy = sum(train_accuracy) / len(train_accuracy)\n","average_validation_accuracy = sum(validation_accuracy) / len(validation_accuracy)\n","\n","print(\"Average Training Accuracy:\", average_train_accuracy)\n","print(\"Average Validation Accuracy:\", average_validation_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwQ9pU4_EkpJ","executionInfo":{"status":"ok","timestamp":1703074803841,"user_tz":-330,"elapsed":1111998,"user":{"displayName":"ABIRAMI G","userId":"00751295287036755883"}},"outputId":"31ef0984-5c8f-4c5f-87c2-8b2e5a0ea224"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n"," 6/19 [========>.....................] - ETA: 1:40 - loss: 9.8634 - accuracy: 0.5922 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["19/19 [==============================] - 184s 10s/step - loss: 4.4905 - accuracy: 0.6454 - val_loss: 0.4752 - val_accuracy: 0.8118\n","Epoch 2/20\n","19/19 [==============================] - 77s 4s/step - loss: 0.6300 - accuracy: 0.7462 - val_loss: 0.3778 - val_accuracy: 0.8504\n","Epoch 3/20\n","19/19 [==============================] - 64s 3s/step - loss: 0.4679 - accuracy: 0.8000 - val_loss: 0.2781 - val_accuracy: 0.8874\n","Epoch 4/20\n","19/19 [==============================] - 75s 4s/step - loss: 0.3326 - accuracy: 0.8555 - val_loss: 0.2323 - val_accuracy: 0.9025\n","Epoch 5/20\n","19/19 [==============================] - 61s 3s/step - loss: 0.2495 - accuracy: 0.8958 - val_loss: 0.2035 - val_accuracy: 0.9210\n","Epoch 6/20\n","19/19 [==============================] - 78s 4s/step - loss: 0.3478 - accuracy: 0.8487 - val_loss: 0.5376 - val_accuracy: 0.7681\n","Epoch 7/20\n","19/19 [==============================] - 63s 3s/step - loss: 0.3411 - accuracy: 0.8538 - val_loss: 0.1930 - val_accuracy: 0.9277\n","Epoch 8/20\n","19/19 [==============================] - 62s 3s/step - loss: 0.2422 - accuracy: 0.8975 - val_loss: 0.1676 - val_accuracy: 0.9328\n","Epoch 9/20\n","19/19 [==============================] - 74s 4s/step - loss: 0.1729 - accuracy: 0.9277 - val_loss: 0.1406 - val_accuracy: 0.9462\n","Epoch 10/20\n","19/19 [==============================] - 69s 4s/step - loss: 0.1985 - accuracy: 0.9277 - val_loss: 0.1145 - val_accuracy: 0.9580\n","Epoch 11/20\n","19/19 [==============================] - 63s 3s/step - loss: 0.1631 - accuracy: 0.9378 - val_loss: 0.1129 - val_accuracy: 0.9513\n","Epoch 12/20\n","19/19 [==============================] - 76s 4s/step - loss: 0.1794 - accuracy: 0.9311 - val_loss: 0.2557 - val_accuracy: 0.8908\n","Epoch 13/20\n","19/19 [==============================] - 61s 3s/step - loss: 0.1793 - accuracy: 0.9176 - val_loss: 0.0814 - val_accuracy: 0.9748\n","Epoch 14/20\n","19/19 [==============================] - 67s 4s/step - loss: 0.1192 - accuracy: 0.9479 - val_loss: 0.1342 - val_accuracy: 0.9445\n","Epoch 15/20\n","19/19 [==============================] - 61s 3s/step - loss: 0.1269 - accuracy: 0.9597 - val_loss: 0.0948 - val_accuracy: 0.9697\n","Epoch 16/20\n","19/19 [==============================] - 76s 4s/step - loss: 0.1214 - accuracy: 0.9546 - val_loss: 0.0740 - val_accuracy: 0.9697\n","Epoch 17/20\n","19/19 [==============================] - 61s 3s/step - loss: 0.1295 - accuracy: 0.9630 - val_loss: 0.0680 - val_accuracy: 0.9714\n","Epoch 18/20\n","19/19 [==============================] - 76s 4s/step - loss: 0.1153 - accuracy: 0.9563 - val_loss: 0.0541 - val_accuracy: 0.9748\n","Epoch 19/20\n","19/19 [==============================] - 81s 4s/step - loss: 0.1420 - accuracy: 0.9462 - val_loss: 0.1012 - val_accuracy: 0.9546\n","Epoch 20/20\n","19/19 [==============================] - 62s 3s/step - loss: 0.1124 - accuracy: 0.9647 - val_loss: 0.0642 - val_accuracy: 0.9765\n","Average Training Accuracy: 0.8938655525445938\n","Average Validation Accuracy: 0.9242016851902009\n"]}]}]}